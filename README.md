# cs189 project Week 7: Bagging

<b>Navigating the file:</b>    
<br/>
This repository will help students wil prior experience with EE16A, EE16B, CS61B to learn the concept of bagging. 
The repository consists of the following items. Please click on the corresponding items to access/download the files.  
1. Slide deck on Bagging in pdf form (Bagging_Slides.pdf)  
1. Note on Bagging in pdf form (Bagging_Notes.pdf)  
1. Ipynb notebook of a working coding assignment for students to do in approximately 8-9 hours (Bagging_code_assignment.ipynb)
1. Ipynb notebook of solutions for the coding assignment (Bagging_code_solution.ipynb)
1. Quiz questions (Bagging_Quiz.pdf)  
1. A dataset you will work with through the code assignment (Admission.csv)

As a student, you will first read through the Notes.pdf and gain a theoretical knowledge of bagging related concepts. Then, you can take a quick quiz to check your basic understanding of the key concepts. The slide deck will also help you gain an overarching understanding of the material. The coding assignment is for you to get your hands dirty. You will implement naive polynomial regression bagging to more sophisticated random forest. After you did your work check your answers with solution.  


<b>Learning Objective:</b>  
The lecture note is theoretically based and aims to connect pieces of machine learning concepts related to bagging together for the student. The note reviews machine learning concepts such as bias and variance, overfitting, bootstrapping and lead naturally to the idea of aggregated bootstrapping - bagging, in the end. Our goal is to let the student discover the internal relationship between machine learning concepts and derive the idea of bagging under our guidance. In the beginning of the note,  we direct student to the orginal paper of bagging and encourage them to skim it in an attempt to develop paper reading and skimming skill of the students. We then poses meaningful bagging questions for the student to think along throughout the whole learning process. Student will then see familiar terms such as bias and variance, bootstrap and k-fold validation and uncover the inner relationship between them. A bagging example, random forest is introduced in the end, with a slight recap of decision tree.




